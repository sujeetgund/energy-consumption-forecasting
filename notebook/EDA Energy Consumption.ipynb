{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e233234",
   "metadata": {},
   "source": [
    "## Energy Consumption Forecasting for Indian States\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e05101",
   "metadata": {},
   "source": [
    "#### Life cycle of this project\n",
    "\n",
    "- Understanding the Problem Statement\n",
    "- Data Collection\n",
    "- Data Checks to perform\n",
    "- Exploratory data analysis\n",
    "- Data Pre-Processing\n",
    "- Model Training\n",
    "- Choose best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcea981",
   "metadata": {},
   "source": [
    "### 1) Problem statement\n",
    "- India’s diverse energy consumption patterns across states make it difficult for grid operators to efficiently balance supply and demand. This project aims to develop a forecasting model using historical state-wise energy consumption data to improve resource allocation, prevent blackouts, and promote sustainable energy practices.\n",
    "\n",
    "\n",
    "\n",
    "### 2) Data Collection\n",
    "- Dataset Source - https://www.kaggle.com/datasets/twinkle0705/state-wise-power-consumption-in-india\n",
    "- This data is in the form of a time series for a period of 17 months beginning from 2nd Jan 2019 till 23rd May 2020.\n",
    "- It has 16.6k rows of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b1355f",
   "metadata": {},
   "source": [
    "### 2.1 Import Data and Required Packages\n",
    "####  Importing Pandas, Numpy, Matplotlib, Seaborn and Warings Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eaae1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caeb0bb",
   "metadata": {},
   "source": [
    "#### Import the CSV Data as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57907087",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/long_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8fd8a",
   "metadata": {},
   "source": [
    "#### Show Top 5 Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1a2a0b",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>States</th>\n",
       "      <th>Regions</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Punjab</td>\n",
       "      <td>NR</td>\n",
       "      <td>31.519974</td>\n",
       "      <td>75.980003</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>119.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>NR</td>\n",
       "      <td>28.450006</td>\n",
       "      <td>77.019991</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>130.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>NR</td>\n",
       "      <td>26.449999</td>\n",
       "      <td>74.639981</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>234.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>NR</td>\n",
       "      <td>28.669993</td>\n",
       "      <td>77.230004</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>85.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UP</td>\n",
       "      <td>NR</td>\n",
       "      <td>27.599981</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>313.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      States Regions   latitude  longitude                Dates  Usage\n",
       "0     Punjab      NR  31.519974  75.980003  02/01/2019 00:00:00  119.9\n",
       "1    Haryana      NR  28.450006  77.019991  02/01/2019 00:00:00  130.3\n",
       "2  Rajasthan      NR  26.449999  74.639981  02/01/2019 00:00:00  234.1\n",
       "3      Delhi      NR  28.669993  77.230004  02/01/2019 00:00:00   85.8\n",
       "4         UP      NR  27.599981  78.050006  02/01/2019 00:00:00  313.9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a49220",
   "metadata": {},
   "source": [
    "#### Shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "417e5820",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['States', 'Regions', 'latitude', 'longitude', 'Dates', 'Usage'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041aa39d",
   "metadata": {},
   "source": [
    "### 2.2 Dataset information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3cff9d",
   "metadata": {},
   "source": [
    "- States : Indian States (33 unique values including union territories)\n",
    "- Regions : Indian Region from where the data is  -> (NR, NER, WR, SR, ER)\n",
    "- latitude : Latitude of the location\n",
    "- longitude : Longitude of the location \n",
    "- Dates : Comple date and time (DD/MM/YYYY hh:mm:ss)\n",
    "- Usage : Electricity usage in Mega Units (MU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c4b61b",
   "metadata": {},
   "source": [
    "### 3. Data Checks to perform\n",
    "\n",
    "- Check Missing values\n",
    "- Check Duplicates\n",
    "- Check data type\n",
    "- Check the number of unique values of each column\n",
    "- Check statistics of data set\n",
    "- Check various categories present in the different categorical column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d4123",
   "metadata": {},
   "source": [
    "### 3.1 Check Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "707d6a7b",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "States       0\n",
       "Regions      0\n",
       "latitude     0\n",
       "longitude    0\n",
       "Dates        0\n",
       "Usage        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f7b83",
   "metadata": {},
   "source": [
    "#### There are no missing values in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5840ff7f",
   "metadata": {},
   "source": [
    "### 3.2 Check Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae16686e",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7ae8e",
   "metadata": {},
   "source": [
    "#### There are 12 duplicates values in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "862a3976",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>States</th>\n",
       "      <th>Regions</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>NER</td>\n",
       "      <td>27.100399</td>\n",
       "      <td>93.616601</td>\n",
       "      <td>08/07/2019 00:00:00</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6065</th>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>NER</td>\n",
       "      <td>27.100399</td>\n",
       "      <td>93.616601</td>\n",
       "      <td>08/07/2019 00:00:00</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6102</th>\n",
       "      <td>Mizoram</td>\n",
       "      <td>NER</td>\n",
       "      <td>23.710399</td>\n",
       "      <td>92.720015</td>\n",
       "      <td>09/07/2019 00:00:00</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135</th>\n",
       "      <td>Mizoram</td>\n",
       "      <td>NER</td>\n",
       "      <td>23.710399</td>\n",
       "      <td>92.720015</td>\n",
       "      <td>09/07/2019 00:00:00</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6163</th>\n",
       "      <td>Sikkim</td>\n",
       "      <td>ER</td>\n",
       "      <td>27.333330</td>\n",
       "      <td>88.616647</td>\n",
       "      <td>10/07/2019 00:00:00</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6167</th>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>NER</td>\n",
       "      <td>25.570492</td>\n",
       "      <td>91.880014</td>\n",
       "      <td>10/07/2019 00:00:00</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6168</th>\n",
       "      <td>Mizoram</td>\n",
       "      <td>NER</td>\n",
       "      <td>23.710399</td>\n",
       "      <td>92.720015</td>\n",
       "      <td>10/07/2019 00:00:00</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6169</th>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NER</td>\n",
       "      <td>25.666998</td>\n",
       "      <td>94.116570</td>\n",
       "      <td>10/07/2019 00:00:00</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6170</th>\n",
       "      <td>Tripura</td>\n",
       "      <td>NER</td>\n",
       "      <td>23.835404</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>10/07/2019 00:00:00</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6196</th>\n",
       "      <td>Sikkim</td>\n",
       "      <td>ER</td>\n",
       "      <td>27.333330</td>\n",
       "      <td>88.616647</td>\n",
       "      <td>10/07/2019 00:00:00</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6200</th>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>NER</td>\n",
       "      <td>25.570492</td>\n",
       "      <td>91.880014</td>\n",
       "      <td>10/07/2019 00:00:00</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6201</th>\n",
       "      <td>Mizoram</td>\n",
       "      <td>NER</td>\n",
       "      <td>23.710399</td>\n",
       "      <td>92.720015</td>\n",
       "      <td>10/07/2019 00:00:00</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NER</td>\n",
       "      <td>25.666998</td>\n",
       "      <td>94.116570</td>\n",
       "      <td>10/07/2019 00:00:00</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6203</th>\n",
       "      <td>Tripura</td>\n",
       "      <td>NER</td>\n",
       "      <td>23.835404</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>10/07/2019 00:00:00</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6275</th>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>NR</td>\n",
       "      <td>30.320409</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>12/07/2019 00:00:00</td>\n",
       "      <td>34.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290</th>\n",
       "      <td>Pondy</td>\n",
       "      <td>SR</td>\n",
       "      <td>11.934994</td>\n",
       "      <td>79.830000</td>\n",
       "      <td>12/07/2019 00:00:00</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>NER</td>\n",
       "      <td>27.100399</td>\n",
       "      <td>93.616601</td>\n",
       "      <td>12/07/2019 00:00:00</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6301</th>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NER</td>\n",
       "      <td>25.666998</td>\n",
       "      <td>94.116570</td>\n",
       "      <td>12/07/2019 00:00:00</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6302</th>\n",
       "      <td>Tripura</td>\n",
       "      <td>NER</td>\n",
       "      <td>23.835404</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>12/07/2019 00:00:00</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>NR</td>\n",
       "      <td>30.320409</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>12/07/2019 00:00:00</td>\n",
       "      <td>34.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6323</th>\n",
       "      <td>Pondy</td>\n",
       "      <td>SR</td>\n",
       "      <td>11.934994</td>\n",
       "      <td>79.830000</td>\n",
       "      <td>12/07/2019 00:00:00</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>NER</td>\n",
       "      <td>27.100399</td>\n",
       "      <td>93.616601</td>\n",
       "      <td>12/07/2019 00:00:00</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NER</td>\n",
       "      <td>25.666998</td>\n",
       "      <td>94.116570</td>\n",
       "      <td>12/07/2019 00:00:00</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6335</th>\n",
       "      <td>Tripura</td>\n",
       "      <td>NER</td>\n",
       "      <td>23.835404</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>12/07/2019 00:00:00</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 States Regions   latitude  longitude                Dates  \\\n",
       "6032  Arunachal Pradesh     NER  27.100399  93.616601  08/07/2019 00:00:00   \n",
       "6065  Arunachal Pradesh     NER  27.100399  93.616601  08/07/2019 00:00:00   \n",
       "6102            Mizoram     NER  23.710399  92.720015  09/07/2019 00:00:00   \n",
       "6135            Mizoram     NER  23.710399  92.720015  09/07/2019 00:00:00   \n",
       "6163             Sikkim      ER  27.333330  88.616647  10/07/2019 00:00:00   \n",
       "6167          Meghalaya     NER  25.570492  91.880014  10/07/2019 00:00:00   \n",
       "6168            Mizoram     NER  23.710399  92.720015  10/07/2019 00:00:00   \n",
       "6169           Nagaland     NER  25.666998  94.116570  10/07/2019 00:00:00   \n",
       "6170            Tripura     NER  23.835404  91.279999  10/07/2019 00:00:00   \n",
       "6196             Sikkim      ER  27.333330  88.616647  10/07/2019 00:00:00   \n",
       "6200          Meghalaya     NER  25.570492  91.880014  10/07/2019 00:00:00   \n",
       "6201            Mizoram     NER  23.710399  92.720015  10/07/2019 00:00:00   \n",
       "6202           Nagaland     NER  25.666998  94.116570  10/07/2019 00:00:00   \n",
       "6203            Tripura     NER  23.835404  91.279999  10/07/2019 00:00:00   \n",
       "6275        Uttarakhand      NR  30.320409  78.050006  12/07/2019 00:00:00   \n",
       "6290              Pondy      SR  11.934994  79.830000  12/07/2019 00:00:00   \n",
       "6296  Arunachal Pradesh     NER  27.100399  93.616601  12/07/2019 00:00:00   \n",
       "6301           Nagaland     NER  25.666998  94.116570  12/07/2019 00:00:00   \n",
       "6302            Tripura     NER  23.835404  91.279999  12/07/2019 00:00:00   \n",
       "6308        Uttarakhand      NR  30.320409  78.050006  12/07/2019 00:00:00   \n",
       "6323              Pondy      SR  11.934994  79.830000  12/07/2019 00:00:00   \n",
       "6329  Arunachal Pradesh     NER  27.100399  93.616601  12/07/2019 00:00:00   \n",
       "6334           Nagaland     NER  25.666998  94.116570  12/07/2019 00:00:00   \n",
       "6335            Tripura     NER  23.835404  91.279999  12/07/2019 00:00:00   \n",
       "\n",
       "      Usage  \n",
       "6032    1.4  \n",
       "6065    1.4  \n",
       "6102    1.4  \n",
       "6135    1.4  \n",
       "6163    1.5  \n",
       "6167    4.1  \n",
       "6168    1.4  \n",
       "6169    1.8  \n",
       "6170    2.9  \n",
       "6196    1.5  \n",
       "6200    4.1  \n",
       "6201    1.4  \n",
       "6202    1.8  \n",
       "6203    2.9  \n",
       "6275   34.1  \n",
       "6290    7.4  \n",
       "6296    2.1  \n",
       "6301    2.1  \n",
       "6302    3.5  \n",
       "6308   34.1  \n",
       "6323    7.4  \n",
       "6329    2.1  \n",
       "6334    2.1  \n",
       "6335    3.5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df[df.duplicated(keep=False)]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "226f9677",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_cleaned = df.drop_duplicates()\n",
    "df_cleaned.duplicated().sum()\n",
    "df = df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dfacc8",
   "metadata": {},
   "source": [
    "### 3.3 Check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25f95bc8",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16587 entries, 0 to 16598\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   States     16587 non-null  object \n",
      " 1   Regions    16587 non-null  object \n",
      " 2   latitude   16587 non-null  float64\n",
      " 3   longitude  16587 non-null  float64\n",
      " 4   Dates      16587 non-null  object \n",
      " 5   Usage      16587 non-null  float64\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 907.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check Null and Dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbbf5b4",
   "metadata": {},
   "source": [
    "### 3.4 Checking the number of unique values of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c2b61b6",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "States         33\n",
       "Regions         5\n",
       "latitude       33\n",
       "longitude      32\n",
       "Dates         498\n",
       "Usage        3627\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f6b022",
   "metadata": {},
   "source": [
    "### 3.5 Check statistics of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76c608dc",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16587.000000</td>\n",
       "      <td>16587.000000</td>\n",
       "      <td>16587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.177156</td>\n",
       "      <td>81.788486</td>\n",
       "      <td>103.072539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.147597</td>\n",
       "      <td>7.256201</td>\n",
       "      <td>116.056017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.900373</td>\n",
       "      <td>71.192400</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.820430</td>\n",
       "      <td>76.569993</td>\n",
       "      <td>6.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.835404</td>\n",
       "      <td>78.570026</td>\n",
       "      <td>64.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.333330</td>\n",
       "      <td>88.329947</td>\n",
       "      <td>174.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>33.450000</td>\n",
       "      <td>94.216667</td>\n",
       "      <td>522.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           latitude     longitude         Usage\n",
       "count  16587.000000  16587.000000  16587.000000\n",
       "mean      23.177156     81.788486    103.072539\n",
       "std        6.147597      7.256201    116.056017\n",
       "min        8.900373     71.192400      0.300000\n",
       "25%       19.820430     76.569993      6.700000\n",
       "50%       23.835404     78.570026     64.600000\n",
       "75%       27.333330     88.329947    174.000000\n",
       "max       33.450000     94.216667    522.100000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc41207",
   "metadata": {},
   "source": [
    "#### Insight\n",
    "\n",
    "- Usage shows high variability, with a standard deviation (116.056017) larger than its mean (103.072539)\n",
    "- While the minimum usage is very low (0.300000), the maximum (522.100000) is significantly higher than the 75th percentile (174.000000)\n",
    "- The median usage (64.600000) is much lower than the mean, suggesting a right-skewed distribution\n",
    "- Latitude has the smallest range (24.549627°) compared to longitude (23.024267°), indicating a more compact north-south spread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52d9cb",
   "metadata": {},
   "source": [
    "### 3.7 Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1afd3c09",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>States</th>\n",
       "      <th>Regions</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Punjab</td>\n",
       "      <td>NR</td>\n",
       "      <td>31.519974</td>\n",
       "      <td>75.980003</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>119.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>NR</td>\n",
       "      <td>28.450006</td>\n",
       "      <td>77.019991</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>130.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>NR</td>\n",
       "      <td>26.449999</td>\n",
       "      <td>74.639981</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>234.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>NR</td>\n",
       "      <td>28.669993</td>\n",
       "      <td>77.230004</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>85.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UP</td>\n",
       "      <td>NR</td>\n",
       "      <td>27.599981</td>\n",
       "      <td>78.050006</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>313.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      States Regions   latitude  longitude                Dates  Usage\n",
       "0     Punjab      NR  31.519974  75.980003  02/01/2019 00:00:00  119.9\n",
       "1    Haryana      NR  28.450006  77.019991  02/01/2019 00:00:00  130.3\n",
       "2  Rajasthan      NR  26.449999  74.639981  02/01/2019 00:00:00  234.1\n",
       "3      Delhi      NR  28.669993  77.230004  02/01/2019 00:00:00   85.8\n",
       "4         UP      NR  27.599981  78.050006  02/01/2019 00:00:00  313.9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9081742",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories in 'States' variable:   ['Punjab' 'Haryana' 'Rajasthan' 'Delhi' 'UP' 'Uttarakhand' 'HP' 'J&K'\n",
      " 'Chandigarh' 'Chhattisgarh' 'Gujarat' 'MP' 'Maharashtra' 'Goa' 'DNH'\n",
      " 'Andhra Pradesh' 'Telangana' 'Karnataka' 'Kerala' 'Tamil Nadu' 'Pondy'\n",
      " 'Bihar' 'Jharkhand' 'Odisha' 'West Bengal' 'Sikkim' 'Arunachal Pradesh'\n",
      " 'Assam' 'Manipur' 'Meghalaya' 'Mizoram' 'Nagaland' 'Tripura']\n",
      "Categories in 'Regions' variable:   ['NR' 'WR' 'SR' 'ER' 'NER']\n",
      "latitude:  [31.51997398 28.45000633 26.44999921 28.6699929  27.59998069 30.32040895\n",
      " 31.10002545 33.45       30.71999697 22.09042035 22.2587     21.30039105\n",
      " 19.25023195 15.491997   20.26657819 14.7504291  18.1124     12.57038129\n",
      "  8.90037274 12.92038576 11.93499371 25.78541445 23.80039349 19.82042971\n",
      " 22.58039044 27.3333303  27.10039878 26.7499809  24.79997072 25.57049217\n",
      " 23.71039899 25.6669979  23.83540428]\n",
      "longitude:  [75.98000281 77.01999101 74.63998124 77.23000403 78.05000565 77.16659704\n",
      " 76.24       76.78000565 82.15998734 71.1924     76.13001949 73.16017493\n",
      " 73.81800065 73.0166178  78.57002559 79.0193     76.91999711 76.56999263\n",
      " 79.15004187 79.83000037 87.4799727  86.41998572 85.90001746 88.32994665\n",
      " 88.6166475  93.61660071 94.21666744 93.95001705 91.8800142  92.72001461\n",
      " 94.11657019 91.27999914]\n",
      "Dates:   ['02/01/2019 00:00:00' '03/01/2019 00:00:00' '04/01/2019 00:00:00'\n",
      " '05/01/2019 00:00:00' '06/01/2019 00:00:00' '07/01/2019 00:00:00'\n",
      " '08/01/2019 00:00:00' '09/01/2019 00:00:00' '10/01/2019 00:00:00'\n",
      " '11/01/2019 00:00:00' '12/01/2019 00:00:00' '13/01/2019 00:00:00'\n",
      " '14/01/2019 00:00:00' '15/01/2019 00:00:00' '16/01/2019 00:00:00'\n",
      " '17/01/2019 00:00:00' '18/01/2019 00:00:00' '19/01/2019 00:00:00'\n",
      " '20/01/2019 00:00:00' '21/01/2019 00:00:00' '22/01/2019 00:00:00'\n",
      " '23/01/2019 00:00:00' '24/01/2019 00:00:00' '25/01/2019 00:00:00'\n",
      " '26/01/2019 00:00:00' '27/01/2019 00:00:00' '28/01/2019 00:00:00'\n",
      " '29/01/2019 00:00:00' '30/01/2019 00:00:00' '31/01/2019 00:00:00'\n",
      " '02/02/2019 00:00:00' '03/02/2019 00:00:00' '04/02/2019 00:00:00'\n",
      " '05/02/2019 00:00:00' '06/02/2019 00:00:00' '07/02/2019 00:00:00'\n",
      " '08/02/2019 00:00:00' '09/02/2019 00:00:00' '10/02/2019 00:00:00'\n",
      " '11/02/2019 00:00:00' '12/02/2019 00:00:00' '13/02/2019 00:00:00'\n",
      " '14/02/2019 00:00:00' '15/02/2019 00:00:00' '16/02/2019 00:00:00'\n",
      " '17/02/2019 00:00:00' '18/02/2019 00:00:00' '19/02/2019 00:00:00'\n",
      " '20/02/2019 00:00:00' '21/02/2019 00:00:00' '22/02/2019 00:00:00'\n",
      " '23/02/2019 00:00:00' '24/02/2019 00:00:00' '25/02/2019 00:00:00'\n",
      " '26/02/2019 00:00:00' '27/02/2019 00:00:00' '28/02/2019 00:00:00'\n",
      " '02/03/2019 00:00:00' '03/03/2019 00:00:00' '04/03/2019 00:00:00'\n",
      " '05/03/2019 00:00:00' '06/03/2019 00:00:00' '07/03/2019 00:00:00'\n",
      " '08/03/2019 00:00:00' '09/03/2019 00:00:00' '10/03/2019 00:00:00'\n",
      " '11/03/2019 00:00:00' '12/03/2019 00:00:00' '13/03/2019 00:00:00'\n",
      " '14/03/2019 00:00:00' '15/03/2019 00:00:00' '16/03/2019 00:00:00'\n",
      " '17/03/2019 00:00:00' '18/03/2019 00:00:00' '19/03/2019 00:00:00'\n",
      " '20/03/2019 00:00:00' '21/03/2019 00:00:00' '22/03/2019 00:00:00'\n",
      " '23/03/2019 00:00:00' '24/03/2019 00:00:00' '25/03/2019 00:00:00'\n",
      " '26/03/2019 00:00:00' '27/03/2019 00:00:00' '28/03/2019 00:00:00'\n",
      " '29/03/2019 00:00:00' '30/03/2019 00:00:00' '31/03/2019 00:00:00'\n",
      " '02/04/2019 00:00:00' '03/04/2019 00:00:00' '04/04/2019 00:00:00'\n",
      " '05/04/2019 00:00:00' '06/04/2019 00:00:00' '07/04/2019 00:00:00'\n",
      " '08/04/2019 00:00:00' '09/04/2019 00:00:00' '10/04/2019 00:00:00'\n",
      " '11/04/2019 00:00:00' '12/04/2019 00:00:00' '13/04/2019 00:00:00'\n",
      " '14/04/2019 00:00:00' '15/04/2019 00:00:00' '16/04/2019 00:00:00'\n",
      " '17/04/2019 00:00:00' '18/04/2019 00:00:00' '19/04/2019 00:00:00'\n",
      " '20/04/2019 00:00:00' '21/04/2019 00:00:00' '22/04/2019 00:00:00'\n",
      " '23/04/2019 00:00:00' '24/04/2019 00:00:00' '25/04/2019 00:00:00'\n",
      " '26/04/2019 00:00:00' '27/04/2019 00:00:00' '28/04/2019 00:00:00'\n",
      " '29/04/2019 00:00:00' '30/04/2019 00:00:00' '02/05/2019 00:00:00'\n",
      " '03/05/2019 00:00:00' '04/05/2019 00:00:00' '05/05/2019 00:00:00'\n",
      " '06/05/2019 00:00:00' '07/05/2019 00:00:00' '08/05/2019 00:00:00'\n",
      " '09/05/2019 00:00:00' '10/05/2019 00:00:00' '11/05/2019 00:00:00'\n",
      " '12/05/2019 00:00:00' '13/05/2019 00:00:00' '14/05/2019 00:00:00'\n",
      " '15/05/2019 00:00:00' '16/05/2019 00:00:00' '17/05/2019 00:00:00'\n",
      " '18/05/2019 00:00:00' '19/05/2019 00:00:00' '20/05/2019 00:00:00'\n",
      " '21/05/2019 00:00:00' '22/05/2019 00:00:00' '23/05/2019 00:00:00'\n",
      " '24/05/2019 00:00:00' '25/05/2019 00:00:00' '26/05/2019 00:00:00'\n",
      " '27/05/2019 00:00:00' '28/05/2019 00:00:00' '29/05/2019 00:00:00'\n",
      " '30/05/2019 00:00:00' '31/05/2019 00:00:00' '02/06/2019 00:00:00'\n",
      " '03/06/2019 00:00:00' '04/06/2019 00:00:00' '05/06/2019 00:00:00'\n",
      " '06/06/2019 00:00:00' '07/06/2019 00:00:00' '08/06/2019 00:00:00'\n",
      " '09/06/2019 00:00:00' '10/06/2019 00:00:00' '11/06/2019 00:00:00'\n",
      " '12/06/2019 00:00:00' '13/06/2019 00:00:00' '14/06/2019 00:00:00'\n",
      " '15/06/2019 00:00:00' '16/06/2019 00:00:00' '17/06/2019 00:00:00'\n",
      " '18/06/2019 00:00:00' '19/06/2019 00:00:00' '20/06/2019 00:00:00'\n",
      " '21/06/2019 00:00:00' '22/06/2019 00:00:00' '23/06/2019 00:00:00'\n",
      " '24/06/2019 00:00:00' '25/06/2019 00:00:00' '26/06/2019 00:00:00'\n",
      " '27/06/2019 00:00:00' '28/06/2019 00:00:00' '29/06/2019 00:00:00'\n",
      " '30/06/2019 00:00:00' '01/07/2019 00:00:00' '02/07/2019 00:00:00'\n",
      " '03/07/2019 00:00:00' '04/07/2019 00:00:00' '05/07/2019 00:00:00'\n",
      " '06/07/2019 00:00:00' '07/07/2019 00:00:00' '08/07/2019 00:00:00'\n",
      " '09/07/2019 00:00:00' '10/07/2019 00:00:00' '11/07/2019 00:00:00'\n",
      " '12/07/2019 00:00:00' '13/07/2019 00:00:00' '14/07/2019 00:00:00'\n",
      " '15/07/2019 00:00:00' '16/07/2019 00:00:00' '17/07/2019 00:00:00'\n",
      " '18/07/2019 00:00:00' '19/07/2019 00:00:00' '20/07/2019 00:00:00'\n",
      " '21/07/2019 00:00:00' '22/07/2019 00:00:00' '23/07/2019 00:00:00'\n",
      " '24/07/2019 00:00:00' '25/07/2019 00:00:00' '26/07/2019 00:00:00'\n",
      " '27/07/2019 00:00:00' '28/07/2019 00:00:00' '29/07/2019 00:00:00'\n",
      " '30/07/2019 00:00:00' '31/07/2019 00:00:00' '01/08/2019 00:00:00'\n",
      " '02/08/2019 00:00:00' '03/08/2019 00:00:00' '04/08/2019 00:00:00'\n",
      " '05/08/2019 00:00:00' '06/08/2019 00:00:00' '08/08/2019 00:00:00'\n",
      " '09/08/2019 00:00:00' '10/08/2019 00:00:00' '11/08/2019 00:00:00'\n",
      " '12/08/2019 00:00:00' '13/08/2019 00:00:00' '14/08/2019 00:00:00'\n",
      " '15/08/2019 00:00:00' '16/08/2019 00:00:00' '17/08/2019 00:00:00'\n",
      " '18/08/2019 00:00:00' '19/08/2019 00:00:00' '20/08/2019 00:00:00'\n",
      " '21/08/2019 00:00:00' '22/08/2019 00:00:00' '23/08/2019 00:00:00'\n",
      " '24/08/2019 00:00:00' '25/08/2019 00:00:00' '26/08/2019 00:00:00'\n",
      " '27/08/2019 00:00:00' '28/08/2019 00:00:00' '29/08/2019 00:00:00'\n",
      " '30/08/2019 00:00:00' '31/08/2019 00:00:00' '01/09/2019 00:00:00'\n",
      " '02/09/2019 00:00:00' '03/09/2019 00:00:00' '04/09/2019 00:00:00'\n",
      " '05/09/2019 00:00:00' '06/09/2019 00:00:00' '08/09/2019 00:00:00'\n",
      " '09/09/2019 00:00:00' '10/09/2019 00:00:00' '11/09/2019 00:00:00'\n",
      " '12/09/2019 00:00:00' '13/09/2019 00:00:00' '14/09/2019 00:00:00'\n",
      " '15/09/2019 00:00:00' '16/09/2019 00:00:00' '17/09/2019 00:00:00'\n",
      " '18/09/2019 00:00:00' '19/09/2019 00:00:00' '20/09/2019 00:00:00'\n",
      " '21/09/2019 00:00:00' '22/09/2019 00:00:00' '23/09/2019 00:00:00'\n",
      " '24/09/2019 00:00:00' '25/09/2019 00:00:00' '26/09/2019 00:00:00'\n",
      " '27/09/2019 00:00:00' '28/09/2019 00:00:00' '29/09/2019 00:00:00'\n",
      " '30/09/2019 00:00:00' '01/10/2019 00:00:00' '02/10/2019 00:00:00'\n",
      " '03/10/2019 00:00:00' '04/10/2019 00:00:00' '05/10/2019 00:00:00'\n",
      " '06/10/2019 00:00:00' '08/10/2019 00:00:00' '09/10/2019 00:00:00'\n",
      " '10/10/2019 00:00:00' '11/10/2019 00:00:00' '12/10/2019 00:00:00'\n",
      " '13/10/2019 00:00:00' '14/10/2019 00:00:00' '15/10/2019 00:00:00'\n",
      " '16/10/2019 00:00:00' '17/10/2019 00:00:00' '18/10/2019 00:00:00'\n",
      " '19/10/2019 00:00:00' '20/10/2019 00:00:00' '21/10/2019 00:00:00'\n",
      " '22/10/2019 00:00:00' '23/10/2019 00:00:00' '24/10/2019 00:00:00'\n",
      " '25/10/2019 00:00:00' '26/10/2019 00:00:00' '27/10/2019 00:00:00'\n",
      " '28/10/2019 00:00:00' '29/10/2019 00:00:00' '30/10/2019 00:00:00'\n",
      " '31/10/2019 00:00:00' '01/11/2019 00:00:00' '02/11/2019 00:00:00'\n",
      " '03/11/2019 00:00:00' '04/11/2019 00:00:00' '05/11/2019 00:00:00'\n",
      " '06/11/2019 00:00:00' '08/11/2019 00:00:00' '09/11/2019 00:00:00'\n",
      " '10/11/2019 00:00:00' '11/11/2019 00:00:00' '12/11/2019 00:00:00'\n",
      " '13/11/2019 00:00:00' '14/11/2019 00:00:00' '15/11/2019 00:00:00'\n",
      " '16/11/2019 00:00:00' '17/11/2019 00:00:00' '18/11/2019 00:00:00'\n",
      " '19/11/2019 00:00:00' '20/11/2019 00:00:00' '21/11/2019 00:00:00'\n",
      " '22/11/2019 00:00:00' '23/11/2019 00:00:00' '24/11/2019 00:00:00'\n",
      " '25/11/2019 00:00:00' '26/11/2019 00:00:00' '27/11/2019 00:00:00'\n",
      " '28/11/2019 00:00:00' '29/11/2019 00:00:00' '30/11/2019 00:00:00'\n",
      " '01/12/2019 00:00:00' '02/12/2019 00:00:00' '03/12/2019 00:00:00'\n",
      " '04/12/2019 00:00:00' '05/12/2019 00:00:00' '06/12/2019 00:00:00'\n",
      " '08/12/2019 00:00:00' '09/12/2019 00:00:00' '10/12/2019 00:00:00'\n",
      " '11/12/2019 00:00:00' '12/12/2019 00:00:00' '13/12/2019 00:00:00'\n",
      " '14/12/2019 00:00:00' '15/12/2019 00:00:00' '16/12/2019 00:00:00'\n",
      " '17/12/2019 00:00:00' '18/12/2019 00:00:00' '19/12/2019 00:00:00'\n",
      " '20/12/2019 00:00:00' '21/12/2019 00:00:00' '22/12/2019 00:00:00'\n",
      " '23/12/2019 00:00:00' '24/12/2019 00:00:00' '25/12/2019 00:00:00'\n",
      " '26/12/2019 00:00:00' '27/12/2019 00:00:00' '28/12/2019 00:00:00'\n",
      " '29/12/2019 00:00:00' '30/12/2019 00:00:00' '31/12/2019 00:00:00'\n",
      " '01/01/2020 00:00:00' '02/01/2020 00:00:00' '03/01/2020 00:00:00'\n",
      " '04/01/2020 00:00:00' '05/01/2020 00:00:00' '13/01/2020 00:00:00'\n",
      " '14/01/2020 00:00:00' '15/01/2020 00:00:00' '16/01/2020 00:00:00'\n",
      " '17/01/2020 00:00:00' '18/01/2020 00:00:00' '19/01/2020 00:00:00'\n",
      " '20/01/2020 00:00:00' '21/01/2020 00:00:00' '22/01/2020 00:00:00'\n",
      " '23/01/2020 00:00:00' '24/01/2020 00:00:00' '25/01/2020 00:00:00'\n",
      " '26/01/2020 00:00:00' '27/01/2020 00:00:00' '28/01/2020 00:00:00'\n",
      " '29/01/2020 00:00:00' '30/01/2020 00:00:00' '31/01/2020 00:00:00'\n",
      " '01/02/2020 00:00:00' '02/02/2020 00:00:00' '03/02/2020 00:00:00'\n",
      " '04/02/2020 00:00:00' '05/02/2020 00:00:00' '13/02/2020 00:00:00'\n",
      " '14/02/2020 00:00:00' '15/02/2020 00:00:00' '16/02/2020 00:00:00'\n",
      " '17/02/2020 00:00:00' '18/02/2020 00:00:00' '19/02/2020 00:00:00'\n",
      " '20/02/2020 00:00:00' '21/02/2020 00:00:00' '22/02/2020 00:00:00'\n",
      " '23/02/2020 00:00:00' '24/02/2020 00:00:00' '25/02/2020 00:00:00'\n",
      " '26/02/2020 00:00:00' '27/02/2020 00:00:00' '28/02/2020 00:00:00'\n",
      " '29/02/2020 00:00:00' '01/03/2020 00:00:00' '02/03/2020 00:00:00'\n",
      " '03/03/2020 00:00:00' '04/03/2020 00:00:00' '05/03/2020 00:00:00'\n",
      " '13/03/2020 00:00:00' '14/03/2020 00:00:00' '15/03/2020 00:00:00'\n",
      " '16/03/2020 00:00:00' '17/03/2020 00:00:00' '18/03/2020 00:00:00'\n",
      " '19/03/2020 00:00:00' '20/03/2020 00:00:00' '21/03/2020 00:00:00'\n",
      " '22/03/2020 00:00:00' '23/03/2020 00:00:00' '24/03/2020 00:00:00'\n",
      " '25/03/2020 00:00:00' '26/03/2020 00:00:00' '27/03/2020 00:00:00'\n",
      " '28/03/2020 00:00:00' '29/03/2020 00:00:00' '30/03/2020 00:00:00'\n",
      " '31/03/2020 00:00:00' '01/04/2020 00:00:00' '02/04/2020 00:00:00'\n",
      " '03/04/2020 00:00:00' '04/04/2020 00:00:00' '05/04/2020 00:00:00'\n",
      " '13/04/2020 00:00:00' '14/04/2020 00:00:00' '15/04/2020 00:00:00'\n",
      " '16/04/2020 00:00:00' '17/04/2020 00:00:00' '18/04/2020 00:00:00'\n",
      " '19/04/2020 00:00:00' '20/04/2020 00:00:00' '21/04/2020 00:00:00'\n",
      " '22/04/2020 00:00:00' '23/04/2020 00:00:00' '24/04/2020 00:00:00'\n",
      " '25/04/2020 00:00:00' '26/04/2020 00:00:00' '27/04/2020 00:00:00'\n",
      " '28/04/2020 00:00:00' '29/04/2020 00:00:00' '30/04/2020 00:00:00'\n",
      " '01/05/2020 00:00:00' '02/05/2020 00:00:00' '03/05/2020 00:00:00'\n",
      " '04/05/2020 00:00:00' '05/05/2020 00:00:00' '13/05/2020 00:00:00'\n",
      " '14/05/2020 00:00:00' '15/05/2020 00:00:00' '16/05/2020 00:00:00'\n",
      " '17/05/2020 00:00:00' '18/05/2020 00:00:00' '19/05/2020 00:00:00'\n",
      " '20/05/2020 00:00:00' '21/05/2020 00:00:00' '22/05/2020 00:00:00'\n",
      " '23/05/2020 00:00:00' '01/06/2020 00:00:00' '02/06/2020 00:00:00'\n",
      " '03/06/2020 00:00:00' '04/06/2020 00:00:00' '05/06/2020 00:00:00'\n",
      " '01/07/2020 00:00:00' '02/07/2020 00:00:00' '03/07/2020 00:00:00'\n",
      " '04/07/2020 00:00:00' '05/07/2020 00:00:00' '01/08/2020 00:00:00'\n",
      " '02/08/2020 00:00:00' '03/08/2020 00:00:00' '04/08/2020 00:00:00'\n",
      " '05/08/2020 00:00:00' '01/09/2020 00:00:00' '02/09/2020 00:00:00'\n",
      " '03/09/2020 00:00:00' '04/09/2020 00:00:00' '05/09/2020 00:00:00'\n",
      " '01/10/2020 00:00:00' '02/10/2020 00:00:00' '03/10/2020 00:00:00'\n",
      " '04/10/2020 00:00:00' '05/10/2020 00:00:00' '01/11/2020 00:00:00'\n",
      " '02/11/2020 00:00:00' '03/11/2020 00:00:00' '04/11/2020 00:00:00'\n",
      " '05/11/2020 00:00:00' '01/12/2020 00:00:00' '02/12/2020 00:00:00'\n",
      " '03/12/2020 00:00:00' '04/12/2020 00:00:00' '05/12/2020 00:00:00']\n",
      "Usage:   [119.9 130.3 234.1 ... 362.5 470.5 323.7]\n"
     ]
    }
   ],
   "source": [
    "print(\"Categories in 'States' variable:  \",end=\" \" )\n",
    "print(df['States'].unique())\n",
    "\n",
    "print(\"Categories in 'Regions' variable:  \",end=\" \")\n",
    "print(df['Regions'].unique())\n",
    "\n",
    "print(\"latitude: \",end=\" \" )\n",
    "print(df['latitude'].unique())\n",
    "\n",
    "print(\"longitude: \",end=\" \" )\n",
    "print(df['longitude'].unique())\n",
    "\n",
    "print(\"Dates:  \",end=\" \" )\n",
    "print(df['Dates'].unique())\n",
    "\n",
    "print(\"Usage:  \",end=\" \" )\n",
    "print(df['Usage'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dd97e26",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 3 numerical features : ['latitude', 'longitude', 'Usage']\n",
      "\n",
      "We have 3 categorical features : ['States', 'Regions', 'Dates']\n"
     ]
    }
   ],
   "source": [
    "# define numerical & categorical columns\n",
    "numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "categorical_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "\n",
    "# print columns\n",
    "print('We have {} numerical features : {}'.format(len(numeric_features), numeric_features))\n",
    "print('\\nWe have {} categorical features : {}'.format(len(categorical_features), categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae2822d1",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>States</th>\n",
       "      <th>Regions</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Punjab</td>\n",
       "      <td>NR</td>\n",
       "      <td>31.519974</td>\n",
       "      <td>75.980003</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>119.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>NR</td>\n",
       "      <td>28.450006</td>\n",
       "      <td>77.019991</td>\n",
       "      <td>02/01/2019 00:00:00</td>\n",
       "      <td>130.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    States Regions   latitude  longitude                Dates  Usage\n",
       "0   Punjab      NR  31.519974  75.980003  02/01/2019 00:00:00  119.9\n",
       "1  Haryana      NR  28.450006  77.019991  02/01/2019 00:00:00  130.3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd42eda6",
   "metadata": {},
   "source": [
    "### 3.8 Separating Date and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ffbfdf7",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>States</th>\n",
       "      <th>Regions</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16594</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>NER</td>\n",
       "      <td>24.799971</td>\n",
       "      <td>93.950017</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16595</th>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>NER</td>\n",
       "      <td>25.570492</td>\n",
       "      <td>91.880014</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16596</th>\n",
       "      <td>Mizoram</td>\n",
       "      <td>NER</td>\n",
       "      <td>23.710399</td>\n",
       "      <td>92.720015</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16597</th>\n",
       "      <td>Nagaland</td>\n",
       "      <td>NER</td>\n",
       "      <td>25.666998</td>\n",
       "      <td>94.116570</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16598</th>\n",
       "      <td>Tripura</td>\n",
       "      <td>NER</td>\n",
       "      <td>23.835404</td>\n",
       "      <td>91.279999</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          States Regions   latitude  longitude        Date      Time  Usage\n",
       "16594    Manipur     NER  24.799971  93.950017  2020-12-05  00:00:00    2.5\n",
       "16595  Meghalaya     NER  25.570492  91.880014  2020-12-05  00:00:00    5.8\n",
       "16596    Mizoram     NER  23.710399  92.720015  2020-12-05  00:00:00    1.6\n",
       "16597   Nagaland     NER  25.666998  94.116570  2020-12-05  00:00:00    2.1\n",
       "16598    Tripura     NER  23.835404  91.279999  2020-12-05  00:00:00    3.3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'Dates' to datetime using the specific format\n",
    "df['Dates'] = pd.to_datetime(df['Dates'], format='%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "# Separate date and time\n",
    "df['Date'] = pd.to_datetime(df['Dates']).dt.date\n",
    "df['Time'] = pd.to_datetime(df['Dates']).dt.time\n",
    "\n",
    "# Drop the original 'Dates' column\n",
    "df = df.drop('Dates', axis=1)\n",
    "\n",
    "# Reorder columns\n",
    "column_order = ['States', 'Regions', 'latitude', 'longitude', 'Date', 'Time', 'Usage']\n",
    "df = df[column_order]\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "572c8a75",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electricity usage less than 20 MU: States       5659\n",
      "Regions      5659\n",
      "latitude     5659\n",
      "longitude    5659\n",
      "Date         5659\n",
      "Time         5659\n",
      "Usage        5659\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "usage_less_20 = df[df['Usage'] <= 20].count()\n",
    "\n",
    "\n",
    "print(f'Electricity usage less than 20 MU: {usage_less_20}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f9dc718a552478e14f37d36e0ca2ac7de1ac15c04a40a415ea3abc3fe8a0a39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
